El desarrollo de sistemas de aprendizaje autom√°tico (ML) ha evolucionado desde simples prototipos en notebooks hacia aplicaciones robustas que requieren principios de ingenier√≠a de software. En este contexto, MLOps surge como un enfoque que combina las mejores pr√°cticas del desarrollo de software y la operaci√≥n de modelos de ML, facilitando la reproducibilidad, escalabilidad y mantenibilidad de los sistemas de inteligencia artificial.

Una parte fundamental de MLOps es la **implementaci√≥n de buenas pr√°cticas de codificaci√≥n**, que no solo permiten mejorar la calidad del c√≥digo, sino tambi√©n facilitar el trabajo colaborativo, la automatizaci√≥n de flujos de trabajo y la integraci√≥n con herramientas de versionado, testing y despliegue continuo. En esta pr√°ctica se explorar√°n tres pilares clave para lograr un desarrollo m√°s profesional y organizado:

- **Uso de archivos de configuraci√≥n** (Config Files): Separar la l√≥gica del c√≥digo de los par√°metros y configuraciones del sistema facilita la experimentaci√≥n, la reutilizaci√≥n del c√≥digo y la trazabilidad de los cambios.

- **Interfaces de l√≠nea de comandos** (Command Line Interfaces, CLI): Incorporar interfaces CLI robustas y flexibles permite ejecutar scripts de forma controlada y program√°tica, facilitando la integraci√≥n en pipelines automatizados y la ejecuci√≥n reproducible de experimentos.

- **Buenas pr√°cticas de codificaci√≥n**: Aplicar principios como modularidad, documentaci√≥n, tipado, control de errores, pruebas unitarias y seguimiento de estilo (PEP8, linters) permite construir c√≥digo m√°s limpio, escalable y confiable, caracter√≠sticas esenciales para proyectos de ciencia de datos que evolucionan hacia producci√≥n.

## üéØ Objetivos

- Dise√±ar e implementar estructuras de configuraci√≥n externas (YAML, JSON, .env) para separar los par√°metros de ejecuci√≥n de la l√≥gica del c√≥digo, siguiendo principios de limpieza y flexibilidad.

- Explorar distintas formas de construir interfaces de l√≠nea de comandos (CLI) para aplicaciones de ML:

    - Uso de librer√≠as como argparse, click o typer.
    - Construcci√≥n de comandos reutilizables y documentados.
    - Manejo de argumentos, subcomandos y ayuda contextual.

- Aplicar buenas pr√°cticas de codificaci√≥n en el desarrollo de componentes de un proyecto MLOps.

## Gesti√≥n de configuraciones con Hydra
El c√≥digo actual del proyecto utiliza `argparse` para recibir ciertos par√°metros necesarios para la ejecuci√≥n de los scripts; sin embargo, tambi√©n **incorpora otros par√°metros directamente codificados en el cuerpo del programa**. Por ejemplo, el script `stage0_loading.py`, utiliza `argparse` para recibir la URL donde est√° alojado  los datos externos, pero adem√°s incluye valores codificados directamente en el c√≥digo fuente, como la ruta donde se guarda el archivo descargado. Este enfoque limita la flexibilidad y dificulta su uso en distintos entornos o etapas del pipeline.

El uso de valores codificados ("hardcoded") como:

```bash
self.external_data = "data/external"
```

impide modificar rutas de entrada o salida sin alterar directamente el c√≥digo, lo cual va en contra de las buenas pr√°cticas en proyectos MLOps.

Por ello, se propone migrar a un enfoque basado en archivos de configuraci√≥n con [Hydra](https://hydra.cc/), una herramienta moderna que permite manejar par√°metros de manera flexible y desacoplada del c√≥digo, ideal para flujos complejos de entrenamiento, pruebas y despliegue de modelos.

### Propuesta de mejora

Hydra permite manejar configuraciones con archivos `.yaml`, dejando el c√≥digo fuente limpio y desacoplado de decisiones contextuales como rutas de archivos, nombres, etc. A continuaci√≥n los pasos para migrar a Hydra:

1. Instalar Hydra

    Hasta la fecha actual, Hydra no est√° disponible directamente como paquete en los canales est√°ndar de Conda (como `conda-forge` o `defaults`), por lo que la forma recomendada de instalar `hydra-core` es usando `pip`, incluso dentro de un entorno Conda:

    ```bash
    pip install hydra-core
    ```

2. Crear un archivo de configuraci√≥n YAML

    Crea el archivo `configs/data_eng.yaml`, el cual contendr√° todos los par√°metros necesarios para la fase Ingenier√≠a de Datos (Data Enginnering) del flujo de trabajo de MLOPS. Por el momento, el archivo tendra el siguiente contenido:

    ```yaml
    data_source:
        url: "https://raw.githubusercontent.com/jmem-ec/KRRCourse/ccbd6ccf8389ba0988d53fc9300a64da00e6368b/Consignment_pricing.csv"
        external_data_dir: "data/external"
        filename: "Consignment_pricing.csv"
    ```

3. Modificar el script para usar Hydra

    Las siguientes acciones han sido ejecutadas:
    
    - Incorporar en la seccion de importaci√≥n 
        ```python
            import hydra
            from omegaconf import DictConfig
        ```
    
    - Reemplaza el uso de `argparse` por hydra, y usa los valores del archivo `.yaml`

        ```python
        @hydra.main(config_path="../../configs", config_name="data_eng", version_base=None)
        def main(cfg: DictConfig):
            logging.basicConfig(level=logging.INFO)
            data = GetData().get_data(cfg)

        if _name_ == "_main_":
            main()
        ```
        Toma en cuenta que **no puedes llamar directamente** a la funci√≥n decorada con `@hydra.main(...)` como `main()` desde `if __name__ == "__main__":`, porque Hydra necesita controlar el punto de entrada del script para realizar su redirecci√≥n de rutas y configuraci√≥n del entorno de ejecuci√≥n.

    - Modifica la cabecera de la funcion `get_data` 

        ```python
        def get_data(self, config)
        ```

    - Cambia los valores codificados ("hardcoded") usando los valores del archivo `.yaml`
        ```python
        ...
        github_csv_url = config.data_source.url
        
        self.external_data = config.data_source.external_data_dir

        ...
        local_path = os.path.join(self.external_data, config.data_source.filename)
        ```

#### üõ†Ô∏è Tarea

- Por defecto, Hydra escribir√° los resultados en una carpeta de resultados, con una subcarpeta para el d√≠a en que se ejecut√≥ el experimento y, adem√°s, la hora en que se inici√≥. Inspeccione su ejecuci√≥n revisando cada archivo que Hydra ha generado y compruebe que la informaci√≥n ha sido registrada.

- Hydra tambi√©n permite cambiar y a√±adir par√°metros din√°micamente sobre la marcha desde la l√≠nea de comandos:

    - Pruebe a cambiar un par√°metro desde la l√≠nea de comandos.
    ```python
    python src/data_eng/stage0_loading.py data_source.filename=Dataset1.csv
    ```

    - Pruebe a a√±adir un par√°metro desde la l√≠nea de comandos.
    ```python
    python src/data_eng/stage0_loading.py +data_source.additional=50
    ```

- Realice un nuevo experimento utilizando un nuevo archivo de configuraci√≥n en el que cambie un par√°metro de su elecci√≥n. No se le permite cambiar el archivo de configuraci√≥n en el script, sino que deber√≠a poder proporcionarlo como argumento al iniciar el script, por ejemplo, algo como

    ```bash
    python src/data_eng/stage0_loading.py experiment=exp2
    ```

    Le recomendamos que utilice una estructura de archivos como la siguiente:

    ```bash
    |--confs
    |  |--model1.yaml
    |  |--data_eng.yaml
    |  |--experiments
    |     |--exp1.yaml
    |     |--exp2.yaml
    |--data
    |--...
    ```

    Este ser√≠a el archivo base de configuraci√≥n `data_eng.yaml`, que incluye un grupo `experiment`:

    ```bash
    defaults:
        - experiment: exp1   # valor por defecto

    data_source:
        url: "https://raw.githubusercontent.com/jmem-ec/KRRCourse/ccbd6ccf8389ba0988d53fc9300a64da00e6368b/Consignment_pricing.csv"
        external_data_dir: "data/external"
        filename: "Consignment_pricing.csv"
    ```

    Experimento 1: configs/experiments/exp1.yaml

    ```bash
    data_source:
        filename: "Dataset1.csv"
    ```

    Experimento 2: configs/experiments/exp2.yaml

    ```bash
    data_source:
        filename: "Dataset2.csv"
    ```

    Ahora puede probar los experimentos

    ```bash
    # Ejecuta con la configuraci√≥n por defecto (exp1)
    python src/data_eng/stage0_loading.py

    # Ejecuta con la configuraci√≥n de experimento 2
    python src/data_eng/stage0_loading.py experiment=exp2
    ```

- Modifique el script `stage1_ingestion.py` para que obtenga los par√°metros necesarios desde el archivo de configuraci√≥n `data_eng.yaml`, en lugar de tenerlos codificados directamente en el script.
En particular, aseg√∫rate de que el archivo `data_eng.yaml` incluya la siguiente secci√≥n:

    ```bash
    raw_data:
        raw_data_dir: "data/raw"
        raw_filename: "Dataset.csv"
    ```
