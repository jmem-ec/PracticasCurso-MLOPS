Despu√©s de configurar el almacenamiento remoto y configurar el inicio de un proyecto DVC para versionar datos y modelos, el siguiente paso es automatizar y estructurar flujos de trabajo mediante la construcci√≥n de un pipeline de experimentos. Un pipeline permite encadenar etapas del proceso (por ejemplo, preprocesamiento, entrenamiento y evaluaci√≥n) de forma reproducible y trazable, facilitando el trabajo colaborativo y la experimentaci√≥n sistem√°tica.

Esta pr√°ctica est√° basada en el conjunto de datos previamente versionado con DVC (`data/raw/Dataset.csv`). Este archivo es la fuente de datos para entrenar el modelo de predicci√≥n. Recordemos que el proyecto implementado tiene tres etapas principales:

- Preprocesamiento de datos (limpieza, extracci√≥n de caracter√≠sticas, y divisi√≥n de datos)
- Entrenamiento del modelo
- Evaluaci√≥n del modelo

## üéØ Objetivos

- Construir un pipeline de ML utilizando DVC.
- Declarar las dependencias y salidas de cada etapa del flujo de trabajo.
- Ejecutar y rastrear autom√°ticamente los cambios en los datos o en el c√≥digo que afecten el resultado del experimento.
- Comprender c√≥mo DVC administra los archivos intermedios y el modelo final en cada etapa.

## üõ†Ô∏è Requisitos

Debes contar con los siguientes scripts organizados en tu proyecto:

- **stage2_cleaning.py**: Realiza la limpieza y preprocesamiento de los datos brutos, eliminando valores inconsistentes o faltantes y estandarizando formatos para su posterior an√°lisis.

- **stage3_labeling.py**: Extrae caracter√≠sticas relevantes desde la fuente de datos y asigna etiquetas necesarias para el entrenamiento supervisado del modelo.

- **stage4_splitting.py**: Divide el conjunto de datos procesado en subconjuntos de entrenamiento y prueba, asegurando una distribuci√≥n adecuada para la validaci√≥n del modelo.

- **stage1_2_train_evaluate.py**: Entrena el modelo utilizando el conjunto de entrenamiento y eval√∫a su desempe√±o sobre el conjunto de prueba, generando m√©tricas de rendimiento clave.

!!! warning "Advertencia:"
    Los pipelines propuestos a continuaci√≥n est√°n basados en la estructura del repositorio (creado en la pr√°ctica [Estructura del Proyecto](../entorno/p5.md) y especializado en las pr√°cticas [Versionado del C√≥digo](../entrenamiento/p7.md), [Empaquetado y gesti√≥n de dependencias](../entrenamiento/p8.md) y [Buenas pr√°cticas de codificaci√≥n](../entrenamiento/p9.md)). Sin embargo, es posible crear otros scripts y crear pipelines espec√≠ficos para las necesidades de su proyecto.


## Creaci√≥n de pipelines
DVC construye un pipeline basado en tres componentes: Entradas (Inputs), Salidas (Outputs) y Comando (Command). Por ejemplo, para la etapa de limpieza de datos, estos ser√≠an los componentes:

- **Entradas**: archivo `data/raw/Dataset.csv` y el script `stage2_cleaning.py`
- **Salidas**: archivo `data/interim/Cleaned_Dataset.csv`
- **Comando**: `python3 stage2_cleaning.py`

Para crear esta etapa, utilizamos el comando `dvc stage add` de la siguiente forma:

```bash
dvc stage add -n limpieza \
  -d src/data_eng/stage2_cleaning.py -d data/raw/Dataset.csv \
  -o data/interim/Cleaned_Dataset.csv \
  python3 src/data_eng/stage2_cleaning.py
```

Aqu√≠ nombramos esta etapa como "limpieza" usando la opci√≥n `-n`. Tambi√©n definimos las entradas con la opci√≥n `-d` y las salidas con la opci√≥n `-o`. El comando que se ejecuta siempre va al final del comando `dvc stage add`, sin ninguna opci√≥n.

!!! warning "Consejo"
    Los archivos de salida se agregan al control de DVC cuando reproduces una etapa de DVC. Cuando finalices tu experimento, recuerda usar dvc push para versionar no solo los datos usados sino tambi√©n los resultados generados durante el experimento.

En este punto, es posible que hayas notado que se crearon dos archivos nuevos: `dvc.yaml` y `dvc.lock`.
El primero es responsable de guardar lo que se describi√≥ en cada comando `dvc stage add`. Por lo tanto, si deseas crear o modificar una etapa espec√≠fica, es posible editar directamente el archivo `dvc.yaml`. El archivo actual se ver√≠a as√≠:

```bash
stages:
  limpieza:
    cmd: python3 src/data_eng/stage2_cleaning.py
    deps:
    - src/data_eng/stage2_cleaning.py
    - data/raw/Dataset.csv
    outs:
    - data/interim/Cleaned_Dataset.csv
```

El segundo archivo creado es `dvc.lock`. Este tambi√©n es un archivo YAML y su funci√≥n es similar a los archivos `.dvc`. En su interior, podemos encontrar la ruta y un c√≥digo hash para cada archivo de cada etapa, lo que permite a DVC hacer seguimiento de los cambios. Este seguimiento es importante porque ahora DVC puede saber cu√°ndo una etapa debe ejecutarse de nuevo o no, bas√°ndose en si sus dependencias cambiaron.
El pipeline actual se ve as√≠:

![Pipeline_1](recursos/FaseLimpieza.png)


## Actualizaci√≥n de las dem√°s etapas del pipeline

A partir de este punto, puedes definir y actualizar las siguientes etapas del pipeline directamente en el archivo `dvc.yaml`. Cada tarea o paso del flujo de trabajo se especifica como una etapa (stage) dentro de dicho archivo, siguiendo la estructura del pipeline. Por ejemplo:

```yaml
stages:
  limpieza:
    cmd: python3 src/data_eng/stage2_cleaning.py
    deps:
    - data/raw/Dataset.csv
    - src/data_eng/stage2_cleaning.py
    outs:
    - data/interim/Cleaned_Dataset.csv

  extraccion_caracteristicas:
    cmd: python3 src/data_eng/stage3_labeling.py
    deps:
    - data/interim/Cleaned_Dataset.csv
    - src/data_eng/stage3_labeling.py
    outs:
    - data/processed/Processed_Dataset.csv

  division:
    cmd: python3 src/data_eng/stage4_splitting.py
    deps:
    - data/processed/Processed_Dataset.csv
    - src/data_eng/stage4_splitting.py
    outs:
    - data/processed/Train_Dataset.csv
    - data/processed/Test_Dataset.csv

  entrenamiento_evaluacion:
    cmd: python3 src/model_eng/stage1_2_train_evaluate.py
    deps:
    - data/processed/Test_Dataset.csv
    - data/processed/Train_Dataset.csv
    - src/model_eng/stage1_2_train_evaluate.py
    params:
      - configs/model_eng.yaml:
        - RandomizedSearchCV.scoring
        - RandomizedSearchCV.n_iter
    outs:
    - models/model_rf.pkl
    metrics:
    - reports/scores.json
```

Entre las etapas definidas en el archivo `dvc.yaml`, a continuaci√≥n se describe en detalle la etapa **entrenamiento_evaluacion**:

Esta etapa forma parte del pipeline de DVC y tiene como objetivo entrenar y evaluar el modelo de aprendizaje autom√°tico utilizando conjuntos de datos previamente procesados:

- `entrenamiento_evaluacion`: es el indentificador de la etapa.
- `cmd: python3 src/model_eng/stage1_2_train_evaluate.py`: Este es el script que se ejecuta cuando se corre esta etapa. En este caso, se trata de un script en Python que:

    - Entrena el modelo y eval√∫a su desempe√±o.
    - Guarda el modelo entrenado y las m√©tricas.

- `deps`:
    - `data/processed/Test_Dataset.csv`
    - `data/processed/Train_Dataset.csv`
    - `src/model_eng/stage1_2_train_evaluate.py`

      Estas son las entradas que DVC monitorea para saber si el stage debe volver a ejecutarse. Si alguno de estos archivos cambia, DVC vuelve a ejecutar el stage. Aqu√≠ se incluyen:

      - Los datos de entrenamiento y prueba procesados.
      - El script de entrenamiento/evaluaci√≥n.

- `params:`
    - `configs/model_eng.yaml:`
      - `RandomizedSearchCV.scoring`
      - `RandomizedSearchCV.n_iter`

    Estos son par√°metros que vienen de un archivo YAML externo (`configs/model_eng.yaml`) y que el script usa. Si cambias estos valores, DVC detectar√° el cambio y volver√° a ejecutar el stage.

- `outs:`
    - `models/model_rf.pkl`

    La salida es el modelo entrenado que se guarda como resultado. DVC lo versiona autom√°ticamente.

- `metrics:`
    - `reports/scores.json`

    En DVC las m√©tricas se pueden mostrar, comparar entre versiones y usarlas en visualizaciones. Para el caso del proyecto las m√©tricas a incluir est√°n en el archivo JSON `reports/scores.json`, el cual contiene m√©tricas del modelo, como rmse, r2_score, mse, train_score, etc. 

El pipeline que representa el proyecto quedar√≠a as√≠:

![Pipeline_2](recursos/Pipeline.png)

## Generar m√©tricas
  
Es importante notar que en la etapa **entrenamiento_evaluacion** usamos la opci√≥n `metrics`. Esto es relevante porque ahora podemos almacenar las m√©tricas generadas por cada experimento.
Si ejecutamos el comando:

```bash
dvc metrics show
```

podremos ver qu√© tan bueno fue el experimento, ya que este comando muestra las m√©tricas guardadas en el archivo `scores.json`.

```bash
$ dvc metrics show
Path                  accuracy    f1       precision    recall        
results/scores.json  0.84973     0.90747  0.8719       0.94607
```
